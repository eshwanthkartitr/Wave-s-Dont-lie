{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from scipy.signal import spectrogram\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from scipy.signal import butter, filtfilt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TTTEEGBlock(nn.Module):\n",
    "    def __init__(self, hidden_size, num_heads=4, head_dim=None, eta=0.001, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = head_dim if head_dim is not None else hidden_size // num_heads\n",
    "        self.eta = eta\n",
    "        \n",
    "        # Initialize with better weight scaling\n",
    "        self.W1 = nn.Parameter(torch.randn(num_heads, self.head_dim, self.head_dim) / np.sqrt(self.head_dim))\n",
    "        self.b1 = nn.Parameter(torch.zeros(num_heads, 1, self.head_dim))\n",
    "        \n",
    "        self.layer_norm = nn.LayerNorm(hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, cache_params=None):\n",
    "        B, L, C = x.shape\n",
    "        \n",
    "        x = self.layer_norm(x)\n",
    "        x = x.reshape(B, L, self.num_heads, self.head_dim)\n",
    "        x = x.permute(0, 2, 1, 3)  # [B, H, L, D]\n",
    "        \n",
    "        if cache_params is None:\n",
    "            output = self.dropout(torch.einsum('bhld,hdf->bhlf', x, self.W1) + self.b1.unsqueeze(0))\n",
    "        else:\n",
    "            with torch.enable_grad():\n",
    "                x_temp = x.detach().requires_grad_()\n",
    "                output_temp = torch.einsum('bhld,hdf->bhlf', x_temp, self.W1) + self.b1.unsqueeze(0)\n",
    "                \n",
    "                # Self-supervised loss: L2 loss + consistency loss\n",
    "                l2_loss = output_temp.pow(2).mean()\n",
    "                # Fix: Ensure proper dimensions for consistency loss\n",
    "                mean_output = output_temp.mean(dim=-1, keepdim=True)  # [B, H, L, 1]\n",
    "                consistency_loss = torch.abs(output_temp - mean_output).mean()\n",
    "                self_supervised_loss = l2_loss + 0.1 * consistency_loss\n",
    "                \n",
    "                # Compute gradients for self-supervised loss\n",
    "                grads = torch.autograd.grad(self_supervised_loss, [self.W1, self.b1], retain_graph=True, create_graph=False)\n",
    "                grad_W1, grad_b1 = grads\n",
    "                \n",
    "                grad_W1 = torch.clamp(grad_W1, -1.0, 1.0)\n",
    "                grad_b1 = torch.clamp(grad_b1, -1.0, 1.0)\n",
    "                \n",
    "                if f'W1_states_{id(self)}' not in cache_params:\n",
    "                    cache_params[f'W1_states_{id(self)}'] = self.W1.clone()\n",
    "                    cache_params[f'b1_states_{id(self)}'] = self.b1.clone()\n",
    "                    cache_params[f'momentum_W1_{id(self)}'] = torch.zeros_like(self.W1)\n",
    "                    cache_params[f'momentum_b1_{id(self)}'] = torch.zeros_like(self.b1)\n",
    "                \n",
    "                momentum = 0.9\n",
    "                cache_params[f'momentum_W1_{id(self)}'] = (\n",
    "                    momentum * cache_params[f'momentum_W1_{id(self)}'] + \n",
    "                    (1 - momentum) * grad_W1\n",
    "                )\n",
    "                cache_params[f'momentum_b1_{id(self)}'] = (\n",
    "                    momentum * cache_params[f'momentum_b1_{id(self)}'] + \n",
    "                    (1 - momentum) * grad_b1\n",
    "                )\n",
    "                \n",
    "                cache_params[f'W1_states_{id(self)}'] -= self.eta * cache_params[f'momentum_W1_{id(self)}']\n",
    "                cache_params[f'b1_states_{id(self)}'] -= self.eta * cache_params[f'momentum_b1_{id(self)}']\n",
    "                \n",
    "                output = self.dropout(torch.einsum('bhld,hdf->bhlf', x, \n",
    "                                    cache_params[f'W1_states_{id(self)}']) + \n",
    "                                    cache_params[f'b1_states_{id(self)}'].unsqueeze(0))\n",
    "        \n",
    "        output = output.permute(0, 2, 1, 3)  # [B, L, H, D]\n",
    "        output = output.reshape(B, L, -1)     # [B, L, H*D]\n",
    "        \n",
    "        return output + x.permute(0, 2, 1, 3).reshape(B, L, -1)  # Residual connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load EEG data from .mat files\n",
    "def load_mat_data(file_path):\n",
    "    data = loadmat(file_path)['data'][0]\n",
    "    inputs, targets = [], []\n",
    "    map = {}\n",
    "    current = 3\n",
    "    for i in range(len(data)):\n",
    "        y = data[i].flatten()\n",
    "        sub = y[0][0]\n",
    "        if y[1][0]=='letter-composing':\n",
    "            continue\n",
    "        if y[2][0] not in ['trial 1','trial 2','trial 3']:\n",
    "            continue\n",
    "        eeg_data = y[3][:6, :]\n",
    "        if sub not in map:\n",
    "            map[sub] = current\n",
    "            current += 1\n",
    "        targets.append(map[sub])\n",
    "        inputs.append(eeg_data)\n",
    "    return np.array(inputs), np.array(targets)\n",
    "\n",
    "def preprocess_eeg(eeg_data):\n",
    "    eeg_data = (eeg_data - np.mean(eeg_data)) / (np.std(eeg_data) + 1e-8)\n",
    "    nyq = 0.5 * 256\n",
    "    low, high = 0.5 / nyq, 45 / nyq\n",
    "    b, a = butter(4, [low, high], btype='band')\n",
    "    return filtfilt(b, a, eeg_data)\n",
    "\n",
    "# Load EEG data from folder structure\n",
    "def load_folder_data(root_path, tasks=['baseline', 'counting', 'logical', 'rotation']):\n",
    "    root = Path(root_path)\n",
    "    X, y = [], []\n",
    "    subjects = [d for d in root.iterdir() if d.is_dir() and d.name in ['eshwa', 'Giri', 'Nithish']]\n",
    "    for subject_idx, subject in enumerate(subjects):\n",
    "        for task in tasks:\n",
    "            session_pattern = f\"OpenBCISession_{subject.name.lower()}_{task}_*\"\n",
    "            sessions = list(subject.glob(session_pattern))\n",
    "            for session in sessions:\n",
    "                raw_files = list(session.glob(\"OpenBCI-RAW-*.txt\"))\n",
    "                for raw_file in raw_files:\n",
    "                    eeg_data = load_eeg_data(raw_file)\n",
    "                    if eeg_data is not None:\n",
    "                        for i in range(6):\n",
    "                            X.append(eeg_data[3750:6250, i])\n",
    "                            y.append(subject_idx)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Data Augmentation Functions\n",
    "def jitter(x, sigma=0.01):\n",
    "    return x + np.random.normal(loc=0., scale=sigma, size=x.shape)\n",
    "\n",
    "def scaling(x, sigma=0.1):\n",
    "    factor = np.random.normal(loc=1.0, scale=sigma, size=(x.shape[0], 1))\n",
    "    return x * factor\n",
    "\n",
    "\n",
    "def create_spectrogram(eeg_data, fs=256, target_area=2500, num_frequencies=50, num_times=50):   \n",
    "    # Calculate the segment length (nperseg) based on the desired number of frequency bins\n",
    "    # The formula for frequency bins is: number of bins = nperseg / 2 + 1\n",
    "    required_nperseg = (num_frequencies - 1) * 2  # Desired frequency bins and corresponding nperseg\n",
    "\n",
    "    # Ensure nperseg doesn't exceed the total signal length\n",
    "    nperseg = min(required_nperseg, len(eeg_data))\n",
    "\n",
    "    noverlap = nperseg // 2  # Overlap (half of segment length by default)\n",
    "\n",
    "    # Compute the spectrogram\n",
    "    frequencies, times, Sxx = spectrogram(\n",
    "        eeg_data, fs=fs, window='hamming', nperseg=nperseg, noverlap=noverlap, detrend='constant', scaling='density'\n",
    "    )\n",
    "\n",
    "    # Ensure we get the expected number of frequency bins\n",
    "    if Sxx.shape[0] < num_frequencies:\n",
    "        print(f\"Warning: Expected {num_frequencies} frequency bins, but got {Sxx.shape[0]}. Padding with zeros.\")\n",
    "        padding = num_frequencies - Sxx.shape[0]\n",
    "        Sxx = np.pad(Sxx, ((0, padding), (0, 0)), mode='constant')\n",
    "    elif Sxx.shape[0] > num_frequencies:\n",
    "        # If the number of frequency bins is more than desired, truncate\n",
    "        Sxx = Sxx[:num_frequencies, :]\n",
    "\n",
    "    # Ensure the number of time bins matches the desired number\n",
    "    if Sxx.shape[1] < num_times:\n",
    "        padding = num_times - Sxx.shape[1]\n",
    "        Sxx = np.pad(Sxx, ((0, 0), (0, padding)), mode='constant')\n",
    "    elif Sxx.shape[1] > num_times:\n",
    "        # Trim time bins if there are more than desired\n",
    "        Sxx = Sxx[:, :num_times]\n",
    "\n",
    "    # Convert to decibels\n",
    "    Sxx = 10 * np.log10(Sxx + 1e-5)\n",
    "\n",
    "    # Normalize the spectrogram\n",
    "    Sxx = (Sxx - Sxx.min()) / (Sxx.max() - Sxx.min() + 1e-8)\n",
    "    return Sxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class TTTCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, eta=0.001):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.eta = eta\n",
    "        \n",
    "        # Hidden state model (f in the paper)\n",
    "        self.hidden_model = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size * 2),\n",
    "            nn.LayerNorm(hidden_size * 2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_size * 2, hidden_size)\n",
    "        )\n",
    "        \n",
    "        # Initialize cache for test-time updates\n",
    "        self.cache_params = {}\n",
    "        \n",
    "    def forward(self, x, hidden, is_training=True):\n",
    "        if is_training:\n",
    "            next_hidden = self.hidden_model(x)\n",
    "        else:\n",
    "            # Test-time training update\n",
    "            with torch.enable_grad():\n",
    "                x_temp = x.detach().requires_grad_()\n",
    "                pred = self.hidden_model(x_temp)\n",
    "                \n",
    "                # Self-supervised loss (as described in paper section 2.1)\n",
    "                l2_loss = pred.pow(2).mean()\n",
    "                consistency_loss = torch.abs(pred - x_temp.mean(dim=-1, keepdim=True)).mean()\n",
    "                loss = l2_loss + 0.1 * consistency_loss\n",
    "                \n",
    "                # Update hidden model parameters\n",
    "                grads = torch.autograd.grad(loss, self.hidden_model.parameters())\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    for param, grad in zip(self.hidden_model.parameters(), grads):\n",
    "                        if f'momentum_{id(param)}' not in self.cache_params:\n",
    "                            self.cache_params[f'momentum_{id(param)}'] = torch.zeros_like(param)\n",
    "                        \n",
    "                        # Momentum update\n",
    "                        self.cache_params[f'momentum_{id(param)}'].mul_(0.9).add_(grad, alpha=0.1)\n",
    "                        param.add_(self.cache_params[f'momentum_{id(param)}'], alpha=-self.eta)\n",
    "                \n",
    "                next_hidden = self.hidden_model(x)\n",
    "                \n",
    "        return next_hidden\n",
    "\n",
    "\n",
    "class TTTRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Create TTT cells for each layer\n",
    "        self.cells = nn.ModuleList([\n",
    "            TTTCell(\n",
    "                input_size if i == 0 else hidden_size,\n",
    "                hidden_size\n",
    "            ) for i in range(num_layers)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x, hidden=None, is_training=True):\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        \n",
    "        if hidden is None:\n",
    "            hidden = [torch.zeros(batch_size, self.hidden_size).to(x.device)\n",
    "                     for _ in range(self.num_layers)]\n",
    "        \n",
    "        outputs = []\n",
    "        for t in range(seq_len):\n",
    "            layer_input = x[:, t, :]\n",
    "            for layer_idx, cell in enumerate(self.cells):\n",
    "                hidden[layer_idx] = cell(layer_input, hidden[layer_idx], is_training)\n",
    "                layer_input = hidden[layer_idx]\n",
    "            outputs.append(layer_input)\n",
    "            \n",
    "        outputs = torch.stack(outputs, dim=1)\n",
    "        return outputs, hidden\n",
    "\n",
    "\n",
    "class EEGClassifier(nn.Module):\n",
    "    def __init__(self, input_channels=1, num_classes=10, dropout_prob=0.5):\n",
    "        super().__init__()\n",
    "        self.cache_params = {}\n",
    "        \n",
    "        # Deeper feature extractor with residual connections\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            # Initial block\n",
    "            nn.Conv2d(input_channels, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 25x25\n",
    "            \n",
    "            # First residual block\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 12x12\n",
    "            \n",
    "            # Second residual block\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 6x6\n",
    "            \n",
    "            # Third block with global pooling\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "        \n",
    "        # Multiple TTT blocks for better adaptation\n",
    "        self.ttt_blocks = nn.ModuleList([\n",
    "            TTTEEGBlock(hidden_size=512, num_heads=8, head_dim=64)\n",
    "            for _ in range(3)  # Increased number of TTT blocks\n",
    "        ])\n",
    "        \n",
    "        # Enhanced classifier with dropout\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Improved decoder for better reconstruction\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 50 * 50)\n",
    "        )    \n",
    "    def forward(self, x, is_source=True):\n",
    "        if len(x.shape) == 3:\n",
    "            x = x.unsqueeze(1)\n",
    "        \n",
    "        # Extract features\n",
    "        features = self.feature_extractor(x)\n",
    "        features = features.squeeze(-1).squeeze(-1)  # [B, 256]\n",
    "        features = features.unsqueeze(1)  # [B, 1, 256]\n",
    "        \n",
    "        # Apply TTT blocks with domain-specific behavior\n",
    "        for block in self.ttt_blocks:\n",
    "            features = block(features, self.cache_params if not is_source else None)\n",
    "        \n",
    "        features = features.squeeze(1)  # [B, 256]\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.classifier(features)\n",
    "        \n",
    "        # Reconstruction\n",
    "        recon = self.decoder(features)\n",
    "        recon = recon.view(-1, 1, 50, 50)\n",
    "        \n",
    "        return logits, recon\n",
    "    \n",
    "def SEBlock(channels):\n",
    "    return nn.Sequential(\n",
    "        nn.AdaptiveAvgPool2d(1),\n",
    "        nn.Conv2d(channels, channels, kernel_size=1),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "\n",
    "\n",
    "def ResidualBlock(in_channels, out_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.GELU(),\n",
    "        SEBlock(out_channels),\n",
    "    )\n",
    "    \n",
    "def frequency_mask(x, max_width=5):\n",
    "    \"\"\"Apply frequency masking\"\"\"\n",
    "    freq_size = x.shape[0]\n",
    "    width = np.random.randint(1, max_width)\n",
    "    start = np.random.randint(0, freq_size - width)\n",
    "    x_masked = x.copy()\n",
    "    x_masked[start:start+width, :] = 0\n",
    "    return x_masked\n",
    "\n",
    "def time_mask(x, max_width=5):\n",
    "    \"\"\"Apply time masking\"\"\"\n",
    "    time_size = x.shape[1]\n",
    "    width = np.random.randint(1, max_width)\n",
    "    start = np.random.randint(0, time_size - width)\n",
    "    x_masked = x.copy()\n",
    "    x_masked[:, start:start+width] = 0\n",
    "    return x_masked\n",
    "    \n",
    "def test_time_adaptation(model, test_loader, adaptation_steps=5, adaptation_lr=0.001):\n",
    "    \"\"\"\n",
    "    Perform test-time adaptation on the model using the test data.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set to eval mode but still allow gradient computation\n",
    "    \n",
    "    # Initialize momentum buffer for each parameter\n",
    "    momentum_buffer = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            momentum_buffer[name] = torch.zeros_like(param)\n",
    "    \n",
    "    beta = 0.9  # momentum coefficient\n",
    "    \n",
    "    for inputs, _ in test_loader:\n",
    "        inputs = inputs.float()\n",
    "        \n",
    "        # Perform multiple adaptation steps\n",
    "        for _ in range(adaptation_steps):\n",
    "            # Forward pass with gradient computation\n",
    "            with torch.enable_grad():\n",
    "                outputs, recon = model(inputs, is_source=False)\n",
    "                \n",
    "                # Compute self-supervised loss\n",
    "                l2_loss = outputs.pow(2).mean()\n",
    "                consistency_loss = torch.abs(outputs - outputs.mean(dim=-1, keepdim=True)).mean()\n",
    "                loss = l2_loss + 0.1 * consistency_loss\n",
    "                \n",
    "                # Compute gradients\n",
    "                loss.backward()\n",
    "                \n",
    "                # Update parameters with momentum\n",
    "                with torch.no_grad():\n",
    "                    for name, param in model.named_parameters():\n",
    "                        if param.grad is not None:\n",
    "                            # Update momentum buffer\n",
    "                            momentum_buffer[name] = beta * momentum_buffer[name] + \\\n",
    "                                                  (1 - beta) * param.grad\n",
    "                            \n",
    "                            # Update parameters\n",
    "                            param.data.add_(momentum_buffer[name], alpha=-adaptation_lr)\n",
    "                \n",
    "                # Zero gradients for next step\n",
    "                model.zero_grad()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, test_loader, num_epochs=100, learning_rate=0.001):\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "    \n",
    "    # One cycle learning rate schedule\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=learning_rate,\n",
    "        epochs=num_epochs,\n",
    "        steps_per_epoch=len(train_loader),\n",
    "        pct_start=0.3,  # Warm-up for 30% of training\n",
    "        div_factor=25,  # Initial lr = max_lr/25\n",
    "        final_div_factor=1000  # Final lr = initial_lr/1000\n",
    "    )\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    scaler = torch.cuda.amp.GradScaler()  # For mixed precision training\n",
    "    \n",
    "    best_val_acc = 0\n",
    "    patience = 15\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, labels in tqdm(train_loader):\n",
    "            inputs = inputs.float()\n",
    "            \n",
    "            # Apply mixup with higher alpha\n",
    "            alpha = 0.4\n",
    "            lam = np.random.beta(alpha, alpha)\n",
    "            batch_size = inputs.size()[0]\n",
    "            index = torch.randperm(batch_size)\n",
    "            mixed_x = lam * inputs + (1 - lam) * inputs[index]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Use mixed precision training\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs, recon = model(mixed_x, is_source=True)\n",
    "                loss = lam * criterion(outputs, labels) + (1 - lam) * criterion(outputs, labels[index])\n",
    "                loss += 0.05 * F.mse_loss(recon, inputs)  # Reduced reconstruction weight\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            scheduler.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Validation with increased TTT steps\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        model = test_time_adaptation(model, val_loader, adaptation_steps=15)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.float()\n",
    "                outputs, _ = model(inputs, is_source=False)\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        val_accuracy = 100. * val_correct / val_total\n",
    "        print(f'\\nEpoch {epoch+1}, Validation Accuracy: {val_accuracy:.2f}%')\n",
    "        \n",
    "        if val_accuracy > best_val_acc:\n",
    "            best_val_acc = val_accuracy\n",
    "            patience_counter = 0\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_acc': val_accuracy,\n",
    "            }, 'best_model.pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered\")\n",
    "                checkpoint = torch.load('best_model.pth')\n",
    "                model.load_state_dict(checkpoint['model_state_dict'])\n",
    "                break\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, data, labels, augment=False):\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for i, eeg in enumerate(tqdm(data, desc=\"Creating spectrograms\")):\n",
    "            for channel in range(eeg.shape[0]):\n",
    "                spectrogram = create_spectrogram(preprocess_eeg(eeg[channel]))\n",
    "                if augment:\n",
    "                    # Add more augmentations\n",
    "                    specs = [\n",
    "                        spectrogram,\n",
    "                        jitter(spectrogram, sigma=0.01),\n",
    "                        scaling(spectrogram, sigma=0.1),\n",
    "                        add_noise(spectrogram, noise_level=0.01),\n",
    "                        time_warp(spectrogram, sigma=2)\n",
    "                    ]\n",
    "                    for spec in specs:\n",
    "                        self.data.append(spec)\n",
    "                        self.labels.append(labels[i])\n",
    "                else:\n",
    "                    self.data.append(spectrogram)\n",
    "                    self.labels.append(labels[i])\n",
    "        \n",
    "        self.data = torch.FloatTensor(np.stack(self.data))\n",
    "        self.data = self.data.unsqueeze(1)\n",
    "        self.labels = torch.LongTensor(self.labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "def add_noise(x, noise_level=0.01):\n",
    "    return x + np.random.randn(*x.shape) * noise_level\n",
    "\n",
    "def time_warp(x, sigma=2):\n",
    "    \"\"\"Apply time warping to a 2D spectrogram.\"\"\"\n",
    "    x = np.array(x)\n",
    "    if len(x.shape) != 2:\n",
    "        raise ValueError(f\"Expected 2D input, got shape {x.shape}\")\n",
    "        \n",
    "    time_steps = np.arange(x.shape[1])\n",
    "    # Generate random warping\n",
    "    warp = np.random.normal(loc=1.0, scale=sigma, size=(1,))\n",
    "    warp_steps = time_steps * warp\n",
    "    \n",
    "    # Ensure warp_steps are within bounds\n",
    "    warp_steps = np.clip(warp_steps, 0, x.shape[1]-1)\n",
    "    \n",
    "    # Apply warping to each frequency bin\n",
    "    warped = np.zeros_like(x)\n",
    "    for i in range(x.shape[0]):\n",
    "        warped[i, :] = np.interp(time_steps, warp_steps, x[i, :])\n",
    "    \n",
    "    return warped\n",
    "\n",
    "def jitter(x, sigma=0.01):\n",
    "    \"\"\"Add random jitter noise.\"\"\"\n",
    "    return x + np.random.normal(0, sigma, x.shape)\n",
    "\n",
    "def scaling(x, sigma=0.1):\n",
    "    \"\"\"Apply random scaling.\"\"\"\n",
    "    factor = np.random.normal(1.0, sigma)\n",
    "    return x * factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 6, 2500) [3 4 5 6 7 8 9]\n",
      "(36, 6, 2500) [0 1 2]\n",
      "Class shape: (120,)\n",
      "Data shape: (120, 6, 2500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating spectrograms: 100%|██████████| 120/120 [00:01<00:00, 105.45it/s]\n"
     ]
    }
   ],
   "source": [
    "def load_eeg_data(file_path, target_range=(0, 500)):\n",
    "    \"\"\"Load EEG data from OpenBCI-RAW files and shift to desired range\"\"\"\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        import matplotlib.pyplot as plt\n",
    "        import numpy as np\n",
    "\n",
    "        # Skip header rows and load only first 6 EEG channels\n",
    "        data = pd.read_csv(file_path, skiprows=6)\n",
    "        eeg_data = data.iloc[:, 1:7].values\n",
    "        \n",
    "        # Shift and scale EEG data to the desired range\n",
    "        eeg_min, eeg_max = eeg_data.min(), eeg_data.max()\n",
    "        scaled_eeg_data = (eeg_data - eeg_min) / (eeg_max - eeg_min)  # Normalize to [0, 1]\n",
    "        scaled_eeg_data = scaled_eeg_data * (target_range[1] - target_range[0]) + target_range[0]\n",
    "        \n",
    "        # Plot the scaled data\n",
    "        # plt.figure(figsize=(12, 8))\n",
    "        # for i in range(6):\n",
    "        #     plt.subplot(6, 1, i + 1)\n",
    "        #     plt.plot(scaled_eeg_data[:, i], linewidth=0.5)\n",
    "        #     plt.title(f'Channel {i + 1}')\n",
    "        #     plt.ylim(target_range[0], target_range[1])  # Set y-limits to match the target range\n",
    "        #     plt.ylabel(\"Amplitude\")\n",
    "        # plt.tight_layout()\n",
    "        # plt.show()\n",
    "\n",
    "        return scaled_eeg_data\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_folder_data(root_path, tasks=['baseline', 'counting', 'logical', 'rotation']):\n",
    "    root = Path(root_path)\n",
    "    X, y = [], []\n",
    "    subjects = [d for d in root.iterdir() if d.is_dir() and d.name in ['eshwa', 'Giri', 'Nithish']]\n",
    "    \n",
    "    for subject_idx, subject in enumerate(subjects):\n",
    "        for task in tasks:\n",
    "            session_pattern = f\"OpenBCISession_{subject.name.lower()}_{task}_*\"\n",
    "            sessions = list(subject.glob(session_pattern))\n",
    "            \n",
    "            for session in sessions:\n",
    "                raw_files = list(session.glob(\"OpenBCI-RAW-*.txt\"))\n",
    "                \n",
    "                for raw_file in raw_files:\n",
    "                    eeg_data = load_eeg_data(raw_file)\n",
    "                    if eeg_data is not None:\n",
    "                        # Ensure we have enough data to slice 2500 samples\n",
    "                        if eeg_data.shape[0] >= 6250:\n",
    "                            # Extract 2500 samples from each of the 6 channels\n",
    "                            X.append(eeg_data[3750:6250, :6])  # Assuming 6 channels\n",
    "                            y.append(subject_idx)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Check if we have the desired number of samples\n",
    "    if X.shape[0] != 36:\n",
    "        print(f\"Warning: Expected 36 samples, but got {X.shape[0]}\")\n",
    "    \n",
    "    return X, y\n",
    "    \n",
    "mat_inputs, mat_targets = load_mat_data('eegdata.mat')\n",
    "folder_inputs, folder_targets = load_folder_data('dataset')\n",
    "\n",
    "# Ensure both datasets havl̥e the same number of dimensions\n",
    "if mat_inputs.ndim == 3 and folder_inputs.ndim == 2:\n",
    "    folder_inputs = folder_inputs[:, np.newaxis, :]  # Add a new axis to match dimensions\n",
    "\n",
    "print(mat_inputs.shape,np.unique(mat_targets))\n",
    "\n",
    "folder_inputs = folder_inputs.transpose(0, 2, 1)\n",
    "print(folder_inputs.shape,np.unique(folder_targets))\n",
    "X = np.concatenate((folder_inputs,mat_inputs), axis=0)\n",
    "y = np.concatenate((folder_targets,mat_targets), axis=0)\n",
    "\n",
    "# Print class and data shapes\n",
    "print(f\"Class shape: {y.shape}\")\n",
    "print(f\"Data shape: {X.shape}\")\n",
    "\n",
    "# Prepare data loaders\n",
    "dataset = EEGDataset(X, y, augment=True)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7,\n",
       "       7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9,\n",
       "       9, 9, 9, 9, 9, 9, 9, 9, 9, 9])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(create_spectrogram(X[0][0]), aspect='auto', cmap='viridis')\n",
    "plt.title('subject id 1,channel 1,task1,trial 1')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "print(y[0])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating spectrograms: 100%|██████████| 120/120 [00:01<00:00, 108.91it/s]\n",
      "C:\\Users\\eshwa\\AppData\\Local\\Temp\\ipykernel_23448\\516978870.py:16: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()  # For mixed precision training\n",
      "C:\\Users\\eshwa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\amp\\grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "  0%|          | 0/158 [00:00<?, ?it/s]C:\\Users\\eshwa\\AppData\\Local\\Temp\\ipykernel_23448\\516978870.py:39: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\eshwa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\amp\\autocast_mode.py:265: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "100%|██████████| 158/158 [01:36<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, Validation Accuracy: 38.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [01:31<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2, Validation Accuracy: 38.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [01:43<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3, Validation Accuracy: 32.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [01:34<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4, Validation Accuracy: 48.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [01:28<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5, Validation Accuracy: 20.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [01:24<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6, Validation Accuracy: 24.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [01:32<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7, Validation Accuracy: 38.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [01:27<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8, Validation Accuracy: 39.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [01:29<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9, Validation Accuracy: 38.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [01:29<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10, Validation Accuracy: 38.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [01:26<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11, Validation Accuracy: 36.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [01:25<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12, Validation Accuracy: 37.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [01:26<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13, Validation Accuracy: 19.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [01:30<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14, Validation Accuracy: 24.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [01:33<00:00,  1.68it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 51\u001b[0m\n\u001b[0;32m     44\u001b[0m model \u001b[38;5;241m=\u001b[39m EEGClassifier(\n\u001b[0;32m     45\u001b[0m     input_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     46\u001b[0m     num_classes\u001b[38;5;241m=\u001b[39mnum_classes,\n\u001b[0;32m     47\u001b[0m     dropout_prob\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m\n\u001b[0;32m     48\u001b[0m )\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Train model with TTT\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Add test loader\u001b[39;49;00m\n\u001b[0;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\n\u001b[0;32m     58\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Evaluation with TTT adaptation\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_with_ttt\u001b[39m(model, data_loader):\n",
      "Cell \u001b[1;32mIn[68], line 58\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, test_loader, num_epochs, learning_rate)\u001b[0m\n\u001b[0;32m     55\u001b[0m val_correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     56\u001b[0m val_total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 58\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtest_time_adaptation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madaptation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m val_loader:\n",
      "Cell \u001b[1;32mIn[67], line 249\u001b[0m, in \u001b[0;36mtest_time_adaptation\u001b[1;34m(model, test_loader, adaptation_steps, adaptation_lr)\u001b[0m\n\u001b[0;32m    245\u001b[0m             momentum_buffer[name] \u001b[38;5;241m=\u001b[39m beta \u001b[38;5;241m*\u001b[39m momentum_buffer[name] \u001b[38;5;241m+\u001b[39m \\\n\u001b[0;32m    246\u001b[0m                                   (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta) \u001b[38;5;241m*\u001b[39m param\u001b[38;5;241m.\u001b[39mgrad\n\u001b[0;32m    248\u001b[0m             \u001b[38;5;66;03m# Update parameters\u001b[39;00m\n\u001b[1;32m--> 249\u001b[0m             \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmomentum_buffer\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43madaptation_lr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m# Zero gradients for next step\u001b[39;00m\n\u001b[0;32m    252\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Update dataset creation\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create source and target datasets\n",
    "dataset = EEGDataset(X, y, augment=True)\n",
    "total_size = len(dataset)\n",
    "train_size = int(0.7 * total_size)\n",
    "val_size = int(0.15 * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "# Split dataset into train, validation, and test sets\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset, \n",
    "    [train_size, val_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(42)  # For reproducibility\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=16, \n",
    "    shuffle=True, \n",
    "    num_workers=0, \n",
    "    pin_memory=False\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=16, \n",
    "    shuffle=False, \n",
    "    num_workers=0, \n",
    "    pin_memory=False\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=16, \n",
    "    shuffle=False, \n",
    "    num_workers=0, \n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "# Initialize model\n",
    "num_classes = 10\n",
    "model = EEGClassifier(\n",
    "    input_channels=1,\n",
    "    num_classes=num_classes,\n",
    "    dropout_prob=0.5\n",
    ")\n",
    "\n",
    "# Train model with TTT\n",
    "trained_model = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,  # Add test loader\n",
    "    num_epochs=20,\n",
    "    learning_rate=0.001\n",
    ")\n",
    "\n",
    "# Evaluation with TTT adaptation\n",
    "def evaluate_with_ttt(model, data_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # Perform test-time adaptation\n",
    "    model = test_time_adaptation(model, data_loader)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs = inputs.float()\n",
    "            outputs, _ = model(inputs, is_source=False)  # Use target domain mode\n",
    "            _, predicted = outputs.max(1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return all_preds, all_labels\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"Evaluating model on test set...\")\n",
    "test_preds, test_labels = evaluate_with_ttt(model, test_loader)\n",
    "\n",
    "# Compute and plot confusion matrix\n",
    "cm = confusion_matrix(test_labels, test_preds, normalize='true')\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    "    display_labels=range(num_classes)\n",
    ")\n",
    "\n",
    "# Plot confusion matrix with improved styling\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "disp.plot(cmap='Blues', ax=ax)\n",
    "plt.title('Normalized Confusion Matrix with TTT Adaptation', fontsize=16, pad=20)\n",
    "plt.xlabel('Predicted Label', fontsize=14, labelpad=10)\n",
    "plt.ylabel('True Label', fontsize=14, labelpad=10)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# Add colorbar with adjusted styling\n",
    "cbar = plt.gcf().axes[-1]\n",
    "cbar.tick_params(labelsize=10)\n",
    "cbar.set_ylabel('Normalized Probability', fontsize=12, labelpad=10)\n",
    "\n",
    "# Adjust layout and display\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print classification metrics\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(test_labels, test_preds))\n",
    "\n",
    "# Save model and results\n",
    "results = {\n",
    "    'confusion_matrix': cm,\n",
    "    'predictions': test_preds,\n",
    "    'true_labels': test_labels\n",
    "}\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'results': results\n",
    "}, 'ttt_model_results.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
